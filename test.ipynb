{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore, firestore_async\n",
    "import firebase_admin\n",
    "\n",
    "credpath = 'scrape/web-scraping-67540-firebase-adminsdk-5qm46-d1a7fa09d5.json'\n",
    "\n",
    "# initialize firebase\n",
    "\n",
    "firebase_admin.initialize_app(credentials.Certificate(credpath))\n",
    "\n",
    "db = firestore.client()\n",
    "\n",
    "# reading data from firebase\n",
    "data = {\"name\": \"Los Angeles\", \"state\": \"CA\", \"country\": \"USA\"}\n",
    "\n",
    "# Add a new doc in collection 'cities' with ID 'LA'\n",
    "# db.collection(\"cities\").document(\"LA\").set(data)\n",
    "\n",
    "totalJobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data(jobs):\n",
    "    if (len(jobs) > 0):\n",
    "        # Link Image Company\n",
    "        linkImageCompany = jobs[8].find('img').get('src')\n",
    "        print(f'Link Image Company: {linkImageCompany}' + '\\n')\n",
    "        # Name Job\n",
    "        nameJob = jobs[8].find('h3', class_='title')\n",
    "        nameJob = nameJob.find('span').text\n",
    "        print(f'Job Name: {nameJob}' + '\\n')\n",
    "        # Company Name\n",
    "        companyJobName = jobs[8].find('a', class_='company').text\n",
    "        print(f'Company Name: {companyJobName}' + '\\n')\n",
    "        # Detail Job Link\n",
    "        detailJobLink = jobs[8].find('a').get('href')\n",
    "        print(f'Detail Job Link: {detailJobLink}' + '\\n')\n",
    "        # Link to Company\n",
    "        linkToCompany = jobs[8].find('a', class_='company').get('href')\n",
    "        print(f'Link to Company: {linkToCompany}' + '\\n')\n",
    "        # Website\n",
    "        website = 'TopCV'\n",
    "        print(f'Website: {website}' + '\\n')\n",
    "        # Simple info\n",
    "        infos = jobs[8].find('div', class_='label-content')\n",
    "        infos = infos.find_all('label')\n",
    "        simpleInfo = []\n",
    "        for info in infos:\n",
    "            temp = info.text\n",
    "            if info.get('class') == ['address']:\n",
    "                address = info.text\n",
    "                print(f'Address: {address}' + '\\n')\n",
    "            if info.get('class') == ['deadline']:\n",
    "                temp = info.text.replace('\\n', '')\n",
    "            simpleInfo.append(temp)\n",
    "        print(f'Simple Info: {simpleInfo}' + '\\n')\n",
    "        # Job Description\n",
    "        html_text = requests.get(detailJobLink).text\n",
    "        soup = BeautifulSoup(html_text, 'lxml')\n",
    "        Description = []\n",
    "        jobDescription = soup.find('div', class_='job-data')\n",
    "        titles = jobDescription.find_all('h3')\n",
    "        contents = jobDescription.find_all('div', class_='content-tab')\n",
    "        count = 0\n",
    "        for content in contents:\n",
    "            # in li tag will be in a new line\n",
    "            if (content.find('li')):\n",
    "                arrLi = ''\n",
    "                liTags = content.find_all('li')\n",
    "                for li in liTags:\n",
    "                    if li == liTags[-1]:\n",
    "                        arrLi += li.text\n",
    "                    else:\n",
    "                        arrLi += li.text + ', '\n",
    "                Description.append({\n",
    "                    'title': titles[count].text,\n",
    "                    'content': arrLi\n",
    "                })\n",
    "            # in p have <br> tag will be in a new line\n",
    "            elif (content.find('p')):\n",
    "                arrP = ''\n",
    "                pTags = content.find_all('p')\n",
    "                for p in pTags:\n",
    "                    # decompose <br> tag\n",
    "                    for br in p.find_all(\"br\"):\n",
    "                        br.replace_with(\", \")\n",
    "                    arrP += p.text\n",
    "            elif content.find('strong') != None:\n",
    "                content.find('strong').decompose()\n",
    "                Description.append({\n",
    "                    'title': titles[count].text,\n",
    "                    'content': content.text\n",
    "                })\n",
    "            else:\n",
    "                Description.append({\n",
    "                    'title': titles[count].text,\n",
    "                    'content': content.text\n",
    "                })\n",
    "            count += 1\n",
    "        print(f'Description: {Description}' + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Jobs_In_TopCV():\n",
    "    url = \"https://www.topcv.vn/\"\n",
    "    search = \"React Native\"\n",
    "    search = search.strip().replace(\" \", \"-\").lower()\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    url = url + \"tim-viec-lam-\"+search+\"?page=1\"\n",
    "\n",
    "    # driver.get(url)\n",
    "\n",
    "    # html_text = requests.get(url).text\n",
    "    # soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    try:\n",
    "        html_text = requests.get(url).text\n",
    "        soup = BeautifulSoup(html_text, 'lxml')\n",
    "    except:\n",
    "        print(\"Không kết nối được server\")\n",
    "        return\n",
    "\n",
    "    jobs = soup.find_all('div', class_='job-item-default job-ta')\n",
    "    jobs_highlight = soup.find_all(\n",
    "        'div', class_='job-item-default bg-highlight job-ta')\n",
    "\n",
    "    Get_Data(jobs)\n",
    "    Get_Data(jobs_highlight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
